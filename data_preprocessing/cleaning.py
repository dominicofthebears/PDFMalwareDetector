import re
import pandas as pd
from sklearn.impute import SimpleImputer
from sklearn.model_selection import train_test_split
from data_preprocessing.discretization import equal_frequency_binning
from data_preprocessing.feature_selection import mutual_info_selection


def cleaning_data(column, col_name):
    column = pd.Series(column).apply(lambda x: re.sub('\([0-9]\)', '', str(x)))
    if col_name == 'text':
        column = pd.Series(column).apply(lambda x: re.sub('0', '-1', str(x)))
    else:
        if col_name == 'header':
            column = pd.Series(column).apply(lambda x: re.sub('[@_!#$^&*()<?/\|}{~:\'\.\[\]\t\s\n]', '', str(x)))
            column = pd.Series(column).apply(lambda x: re.sub('^(?!%|a|-1)[0-9a-zA-Z]*["]*[a-zA-Z0-9]*', '-1', str(x)))
        else:
            column = pd.Series(column).apply(lambda x: re.sub('[@_!#$%^&*()<?/\|}{~:\'\.\[\]]', '', str(x)))
            column = pd.Series(column).apply(lambda x: re.sub('>', '-1', str(x)))
            column = pd.Series(column).apply(lambda x: re.sub('[a-zA-Z]+', '-1', str(x)))
            column = pd.Series(column).apply(lambda x: re.sub('-10', '-1', str(x)))
            column = column.fillna(value=-1)
    return column


def clean_and_fill(dataframe):
    continuous_imputer = SimpleImputer(missing_values=-1, strategy="median")
    categorical_imputer = SimpleImputer(missing_values="-1", strategy="most_frequent")
    for col in dataframe.columns:
        dataframe[col] = cleaning_data(dataframe[col], col)
        if (col != 'header' and col != 'text'):
            dataframe[col] = continuous_imputer.fit_transform(dataframe[col].to_numpy().reshape(-1, 1))
        else:
            dataframe[col] = categorical_imputer.fit_transform(dataframe[col].to_numpy().reshape(-1, 1))
    return dataframe


def main():
    dataframe = pd.read_csv("../datasets/PDFMalware2022.csv").dropna()
    targets = dataframe['Class']
    dataframe = dataframe.drop(columns=["Fine name"])  # dropping useless column
    X_train, X_test, y_train, y_test = train_test_split(dataframe, targets, test_size=0.3,
                                                        stratify=dataframe["Class"], shuffle=True)
    X_train = X_train.drop(columns=["Class"])
    X_test = X_test.drop(columns=["Class"])
    X_train = clean_and_fill(X_train)
    X_test = clean_and_fill(X_test)
    cols_to_drop = mutual_info_selection(X_train, y_train)
    while (len(X_train.columns) > 10):  # in this way we just need to change this value to get a different number of features
        X_train = X_train.drop(columns=cols_to_drop[0])
        X_test = X_test.drop(columns=cols_to_drop[0])
        cols_to_drop.pop(0)

    X_train = pd.concat([X_train, y_train], axis=1)
    X_test = pd.concat([X_test, y_test], axis=1)

    # histogram based outlier detection, not applying that on testing set
    X_train = X_train.drop(X_train[X_train["xref Length"] > 10000].index)
    X_train = X_train.drop(X_train[X_train["metadata size"] > 10000].index)
    X_train = X_train.drop(X_train[X_train["pdfsize"] > 10000].index)
    X_train = X_train.drop(X_train[X_train["endobj"] > 10000].index)

    ContinuousTrain = X_train.copy()
    CategoricalTrain = X_train.copy()
    ContinuousTest = X_test.copy()
    CategoricalTest = X_test.copy()

    ContinuousTrain.to_csv("../datasets/ContinuousTraininingSet.csv", index=False)
    ContinuousTest.to_csv("../datasets/ContinuousTestSet.csv", index=False)

    CategoricalTrain.iloc[:, :-1], CategoricalTest.iloc[:, :-1] = equal_frequency_binning\
        (CategoricalTrain.iloc[:, :-1], CategoricalTest.iloc[:, :-1], 5, "categorical")
    CategoricalTrain.to_csv("../datasets/CategoricalTraininingSet.csv", index=False)
    CategoricalTest.to_csv("../datasets/CategoricalTestSet.csv", index=False)


if __name__ == '__main__':
    main()
