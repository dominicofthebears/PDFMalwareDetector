import pickle
import re
import pandas as pd
from matplotlib import pyplot as plt
from sklearn import tree
from sklearn.ensemble import AdaBoostClassifier
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.model_selection import KFold
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder
from sklearn.tree import DecisionTreeClassifier
from learning.utils import get_rules, save_results


def build_reducted_model(dataframe, clf):
    data = dataframe.iloc[:, :-1].astype('category')
    targets = dataframe.iloc[:, -1]
    kf = KFold(n_splits=5,
               shuffle=True,
               random_state=123
               )
    k = 1
    best_fscore = 0.0
    if clf == "Adaboost":
        pipe = Pipeline([('encoder', OneHotEncoder(handle_unknown='ignore')),
                         ('classifier', AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=2)))])
    else:
        pipe = Pipeline([('encoder', OneHotEncoder(handle_unknown='ignore')),
                         ('classifier', DecisionTreeClassifier(random_state=0, max_depth=5))])
    for train, val in (kf.split(data, targets)):
        print(f'FOLD {k}')
        # fit and predict using classifier
        X_tr = data.to_numpy()[train]
        y_tr = targets.to_numpy()[train]
        X_val = data.to_numpy()[val]
        y_val = targets.to_numpy()[val]
        pipe.fit(X_tr, y_tr)
        y_pred = pipe.predict(X_val)
        cr = classification_report(y_val, y_pred, output_dict=True)
        if float(cr["macro avg"]['f1-score']) > best_fscore:
            best_model = pipe['classifier']
            best_fscore = cr["macro avg"]['f1-score']
            best_val_cr = cr
            best_conf_matrix = confusion_matrix(y_val, y_pred)
        k += 1
    save_results(("Surrogated_" + clf), best_conf_matrix, best_val_cr, "validation")


    best_pipe = Pipeline([('encoder', OneHotEncoder(handle_unknown='ignore')),
                          ('classifier', best_model)])  # train on the overall dataset
    best_pipe.fit(data, targets)

    if clf == "Adaboost":
        estimator = best_pipe['classifier'].estimators_[-1]
    else:
        if clf == "DecisionTree":
            estimator = best_pipe['classifier']
        else:
            raise Exception("Invalid classifier name")

    columns_name = pd.Series(best_pipe['encoder'].get_feature_names_out()).apply(lambda x: re.sub("_", " in range ", x))
    rule_list = get_rules(estimator, feature_names=columns_name, class_names=["Benign", "Malicious"])

    filename = "../models/surrogated_models/" + clf + '_reduced_model.pkl'
    pickle.dump(best_pipe['classifier'], open(filename, 'wb'))

    f = open("../models/surrogated_models/reduced_rules/" + clf + "_reduced_rules.txt", "w")
    for rule in rule_list:
        f.write(rule + "\n")
    f.close()

    plt.figure(figsize=(30, 30))
    columns_name = pd.Series(best_pipe['encoder'].get_feature_names_out()).apply(lambda x: re.sub("_", " in range ", x))
    tree.plot_tree(estimator, feature_names=columns_name, class_names=["Benign", "Malicious"], filled=True, fontsize=6)
    plt.savefig("../models/plots/Surrogated_" + clf + "_treeplot.png", format='png', bbox_inches="tight", dpi=100)


def tree_classify(dataframe, test, clf):
    encoder = OneHotEncoder(handle_unknown="ignore")
    encoder.fit(dataframe.iloc[:, :-1])
    test = encoder.transform(test)

    model = pickle.load(open("./models/surrogated_models/" + clf + "_reduced_model.pkl", 'rb'))
    pred = model.predict(test)
    output_string = "Predicted class for the selected pdf: " + str(pred) + "\n\n"

    if clf == "Adaboost":
        estimator = model.estimators_[-1]
    else:
        if clf == "DecisionTree":
            estimator = model
        else:
            raise Exception("Invalid classifier name")

    columns_name = list(
        pd.Series(encoder.get_feature_names_out()).apply(lambda x: re.sub("_", " in range ", x)))

    feature = estimator.tree_.feature
    node_indicator = estimator.decision_path(test)
    leaf_id = estimator.apply(test)

    sample_id = 0
    node_index = node_indicator.indices[
                 node_indicator.indptr[sample_id]: node_indicator.indptr[sample_id + 1]
                 ]

    output_string += "Decision path: \n"
    for node_id in node_index:
        if leaf_id[sample_id] == node_id:
            continue

        output_string += (
            "decision node {node} : ({feature} = {value}) \n"
            .format(
                node=node_id,
                feature=columns_name[feature[node_id]],
                value=test[sample_id, feature[node_id]],
            )
        )

    return output_string


