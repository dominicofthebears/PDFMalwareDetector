import re
import pandas as pd
from matplotlib import pyplot as plt
from sklearn import tree
from sklearn.ensemble import AdaBoostClassifier
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.model_selection import KFold
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder
from sklearn.tree import DecisionTreeClassifier
from learning.utils import save_results, get_rules, save_rules


def build_model(dataframe, test, clf):
    data = dataframe.iloc[:, :-1].astype('category')
    targets = dataframe.iloc[:, -1]
    kf = KFold(n_splits=5,
               shuffle=True,
               random_state=123
               )
    k = 1
    best_fscore = 0.0
    if clf == "Adaboost":
        pipe = Pipeline([('encoder', OneHotEncoder(handle_unknown = 'ignore')),
                         ('classifier', AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=2)))])
    else:
        pipe = Pipeline([('encoder', OneHotEncoder(handle_unknown = 'ignore')),
                         ('classifier', DecisionTreeClassifier(random_state=0, max_depth=5))])
    for train, val in (kf.split(data, targets)):
        print(f'FOLD {k}')
        # fit and predict using classifier
        X_tr = data.to_numpy()[train]
        y_tr = targets.to_numpy()[train]
        X_val = data.to_numpy()[val]
        y_val = targets.to_numpy()[val]
        pipe.fit(X_tr, y_tr)
        y_pred = pipe.predict(X_val)
        cr = classification_report(y_val, y_pred, output_dict=True)
        if float(cr["macro avg"]['f1-score']) > best_fscore:
            best_model = pipe['classifier']
            best_fscore = cr["macro avg"]['f1-score']
            best_val_cr = cr
            best_conf_matrix = confusion_matrix(y_val, y_pred)
        k += 1
    save_results(clf, best_conf_matrix, best_val_cr, "validation")

    best_pipe = Pipeline([('encoder', OneHotEncoder(handle_unknown='ignore')),
                          ('classifier', best_model)])  # train on the overall dataset
    best_pipe.fit(data, targets)
    test_targets = test.iloc[:, -1]
    predictions = best_pipe.predict(test.iloc[:, :-1])
    test_cr = classification_report(test_targets, predictions, output_dict=True)

    save_results(clf, confusion_matrix(test_targets, predictions), test_cr, "test")
    columns_name = pd.Series(best_pipe['encoder'].get_feature_names_out()).apply(lambda x: re.sub("_", " in range ", x))
    if clf == "Adaboost":
        estimator = best_pipe['classifier'].estimators_[-1]
    else:
        if clf == "DecisionTree":
            estimator = best_pipe['classifier']
        else:
            raise Exception("Invalid classifier name")

    plt.figure(figsize=(15, 15))
    tree.plot_tree(estimator, feature_names=columns_name, class_names=["Benign", "Malicious"], filled=True, fontsize=6)
    save_rules(get_rules(estimator, feature_names=columns_name, class_names=["Benign", "Malicious"]), clf)
    plt.savefig("../models/plots/" + clf + "_treeplot.png", format='png', bbox_inches="tight", dpi=100)


def main():
    dataframe = pd.read_csv("../datasets/CategoricalTraininingSet.csv")
    test = pd.read_csv("../datasets/CategoricalTestSet.csv")
    clf = "Adaboost"
    build_model(dataframe, test, clf)


if __name__ == '__main__':
    main()
